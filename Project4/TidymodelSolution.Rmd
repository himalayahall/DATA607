---
title: "Project 4"
author: "Jawaid Hakim"
date: "`r Sys.Date()`"
output:
  
  pdf_document: 
    toc: true
    number_sections: true
  html_document:
    
    toc: true
    toc_float: true
    number_sections: true
boxlinks: true
urlcolor: blue
always_allow_html: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load library

```{r load-libs}
library(tidyverse)
library(tidymodels)
library(parsnip)
library(textrecipes)
library(readtext)

```

```{r set-seed}
set.seed(1234)
```

```{r}
parallel::detectCores(logical = TRUE)
```

```{r unix-and-mac-onlu}
library(doMC)
registerDoMC(cores = 2)
```

```{r}

```

# Load data

```{r load-data}
df <- read.delim("SMSSpamCollection.txt", 
                  sep = '\t', 
                  col.names = c('cat', 'sms'), 
                  quote = "")
glimpse(df)
```

We can expect the SMS data to be  unbalanced, i.e. number of spam observations is a minority class. Proportion of spam observations is 13.4%. 

```{r}
df %>% 
  count(cat) %>% 
  mutate(prop = n/sum(n))
```


```{r}
df <- df %>%
    mutate(target = ifelse(cat == "ham", 0, 1)) %>%
    mutate(cat = as.factor(cat)) %>%
    mutate(n_words = tokenizers::count_words(sms))
    
glimpse(df)
```


```{r}
df %>% 
  count(cat) %>% 
  mutate(prop = n/sum(n))
```


```{r}
DT::datatable(df %>%
              count(cat),
                extensions = c('FixedColumns',"FixedHeader"),
            options = list(scrollX = TRUE,
                         paging=TRUE,
                         fixedHeader=TRUE))
```


Verify train/test splits have the same proportion of ham/spam as original data set. As we see, the training and test splits have the same proportion as original.

```{r}
sms_split <- initial_split(df, strata = cat)
sms_train <- training(sms_split)
sms_test <- testing(sms_split)

# training set proportions by category
sms_train %>% 
  count(cat) %>% 
  mutate(prop = n/sum(n))

# test set proportions by category
sms_test  %>% 
  count(cat) %>% 
  mutate(prop = n/sum(n))
```


```{r}
sms_train %>%
  mutate(n_words = tokenizers::count_words(sms)) %>%
  ggplot(aes(n_words)) +
  geom_bar() +
  labs(x = "Number of words per sms",
       y = "Number of sms")
```


```{r}
max_words <- 10000
max_length <- 60
```


```{r}
library(themis)
sms_recipe <- recipe(cat ~ sms, data = sms_train) %>%
                step_tokenize(sms, options = list(lowercase = TRUE, strip_punct = TRUE)) %>%
                step_stopwords(sms) %>%
                step_tokenfilter(sms, max_tokens = max_words, min_times = 10) %>%
                step_tfidf(sms) %>%
                step_downsample(cat, under_ratio = 2)
sms_recipe
```

There are a number of models availan
```{r}
library(discrim)
model <- rand_forest() %>%
  set_mode("classification") %>%
  set_engine(engine = "ranger", importance = "impurity")
model
```


```{r}
sms_wf <- workflow() %>%
            add_recipe(sms_recipe) %>%
            add_model(model)
sms_wf
```


```{r}
sms_folds <- vfold_cv(sms_train, strata = cat)
sms_folds
```


```{r}
nb_rs <- fit_resamples(
  sms_wf,
  sms_folds,
  metrics = metric_set(accuracy, roc_auc, precision, recall),
  control = control_resamples(save_pred = TRUE)
)
```


```{r}
nb_rs_metrics <- collect_metrics(nb_rs)
nb_rs_predictions <- collect_predictions(nb_rs)

nb_rs_metrics
```


```{r}
nb_rs_predictions %>%
  group_by(id) %>%
  roc_curve(truth = cat, .pred_ham) %>%
  autoplot() +
  labs(
    color = NULL,
    title = "ROC curve for US Consumer Finance Complaints",
    subtitle = "Each resample fold is shown in a different color"
  )
```

```{r}
conf_mat_resampled(nb_rs, tidy = FALSE) %>%
  autoplot(type = "heatmap")
```

## Compare to Null model

```{r}
null_classification <- null_model() %>%
  set_engine("parsnip") %>%
  set_mode("classification")

null_rs <- workflow() %>%
  add_recipe(sms_recipe) %>%
  add_model(null_classification) %>%
  fit_resamples(
    sms_folds, 
    metrics = metric_set(accuracy, roc_auc, precision, recall),
    control = control_resamples(save_pred = TRUE)
  )
```

The null model has a high **accuracy** (same as proportion of the majority class) and a terrible **roc_auc**.

```{r}
null_rs %>%
  collect_metrics()
```

As expected, the null model simply guesses the majority class *ham* on each prediction.

```{r}
conf_mat_resampled(null_rs, tidy = FALSE) %>%
  autoplot(type = "heatmap")

```

## Fit one final time with all the data

```{r}
final_fitted <- last_fit(sms_wf, sms_split)
```

The final model looks quite good with a **roc_auc** of 0.981.

```{r}
final_metrics <- collect_metrics(final_fitted)
final_predictions <- collect_predictions(final_fitted)

final_metrics
```

And the confusion matrix bears out that tghe model is performing well.
```{r}
final_predictions %>%
  conf_mat(truth = cat, estimate = .pred_class) %>%
  autoplot(type = "heatmap")
```

```{r}
final_predictions  %>%
  roc_curve(truth = cat, .pred_ham) %>%
  autoplot() +
  labs(
    color = NULL,
    title = "ROC curve for classification of SMS messages into ham/spam",
    subtitle = "With final tuned lasso regularized classifier on the test set"
  )
```


