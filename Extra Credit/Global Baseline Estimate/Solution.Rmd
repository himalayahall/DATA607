---
title: "Global Baseline Estimate"
author: "Jawaid Hakim"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: true
    number_sections: true
  html_document:
    includes:
      in_header: header.html
    css: ./lab.css
    highlight: pygments
    theme: cerulean
    toc: true
    toc_float: true
urlcolor: blue
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

# Global Baseline Estimate

Most recommender systems use personalized algorithms like "content management" and "item-item collaborative filtering."  Sometimes non-personalized recommenders are also useful or necessary.  One of the best non-personalized recommender system algorithms is the "Global Baseline Estimate," which is demonstrated in the attached Excel spreadsheet, MovieRatings.xlsx.  We will also walk through this spreadsheet in our 14-Sep-2022 meetup.
Your job here is to use the survey data you collected in your previous assignment, and write the R code that lets you make an item (e.g. movie) recommendation using the Global Baseline Estimate algorithm.  

There needs to be at least one respondent with at least two unrated items. You may modify your survey data if needed.  Your task is to use the global baseline estimate algorithm to determine ratings for unseen items, then recommend an item to at least one of your survey respondents.

# Data

Assumes the input file *MovieRatings.xlsx* has been downloaded from [github](https://github.com/himalayahall/DATA607/tree/main/Extra%20Credit/Global%20Baseline%20Estimate) and installed in the current working directory.  

Let's look at the data sheets. There are 2 input data sheets: *MovieRatings* contains the sample data provided with the assignment and *MyMovieRatings* contains the actual survey data.

```{r find-sheet-names}
readxl::excel_sheets("MovieRatings.xlsx")
```

Load *MovieRatings* sheet to reproduce model *Global Baseline*  provided with the assignment. Otherwise, to reproduce *My Global Baseline*, load *MyMovieRatings*.  

Here we load *MyMovieRatings*.

```{r load-data}
ds <- readxl::read_excel("MovieRatings.xlsx", sheet = "MyMovieRatings")
str(ds)
```

Let's remove the *Critic* column from the data frame. Doing so has the advantage that all remaining columns are numeric and it's easier to perform computations on a data frame with only numeric data.

```{r}
num_ds <- ds %>%
    select(-Critic)
num_ds

num_ds <- num_ds %>%
             mutate_if(is.numeric, function(x) ifelse(x == 0, NA, x))
num_ds
```

# Contruct Global Baseline model

Global Baseline sheets in input XLSX contain the model that is necessary for making predictions. Model *Global Baseline* is for *MovieRatings* data, *My Global Baseline* is for *MyMovieRatings*. 

Let's build the *My Global Baseline* model one piece at a time (as Johnny Cash would say!).

## Compute mean movie rating

Now let's compute the mean movie rating. Note, *mean_movie* matches the model value.

```{r}
all_rat <- unlist(num_ds, use.names = FALSE)    # extract all movie ratings
all_rat <- all_rat[!is.na(all_rat)]             # remove NA

sum_rating <- sum(all_rat, na.rm = TRUE)        # sum all ratings
sum_rating

count_rating <- length(all_rat)                 # count number of ratings
count_rating

mean_movie <- round(sum_rating / count_rating, 2) # compute mean movie rating
mean_movie
```

## Compute movie averages

Compute (movie) averages of all numeric columns. Note, move averages match the model.

```{r}
movie_average <- num_ds %>% 
                    summarise_if(is.numeric, mean, na.rm = TRUE)
movie_average
```

Add 2 rows at the end of data frame: 1^st^ row contains movie averages, 2^nd^ row contains the *movie average - mean movie*. Note, values of both rows matches the model.

```{r}
num_ds <- add_row(num_ds, movie_average)
num_ds <- add_row(num_ds, round(movie_average - mean_movie, 2))
tail(num_ds)
```

## User Average

Compute and add *user average* as column to data frame.

```{r}
num_ds <- num_ds %>%
            mutate('user avg' = rowMeans(., na.rm = TRUE)) 
    
num_ds <- num_ds %>%
            mutate('user avg' = round(num_ds$`user avg`, 2)) 
    
head(num_ds, n = 10)
```

Compute and add *user average - mean movie* as column to data frame.

```{r}
num_ds <- num_ds %>%
            mutate("user avg - mean movie" = round(num_ds$`user avg` - mean_movie, 2)) 
head(num_ds)
```

Extract *critics* and *movies* from original data source.

```{r}
critics <- unlist(ds[, 'Critic'], use.names = FALSE)
critics

movies <- colnames(ds)
movies <- movies[-1]    # remove Critics from movie names
movies
```

Add *movie avg* and *movie avg - mean movie* as rows to critics.

```{r}
critics_expanded <- append(critics, 'movie avg')

critics_expanded <- append(critics_expanded, 'movie avg - mean movie')

critics_expanded
```

Add expanded *critics* columns back into data source. This data frame should be identical in all important aspects to the *My Global Baseline* sheet in input XSLX. 

```{r assemble-global-baseline}
global_baseline <- add_column(num_ds, 'Critic' = critics_expanded, .before = 0)
global_baseline
```

# Predictions

Now that we have our Global Baseline model, let's create a function that predicts the movie rating for any pair of movie and critic.

```{r prediction-function}
me.predictRating <- function(movie, critic) {
            if (! movie %in% colnames(global_baseline)) {     
                print(paste("Error - invalid movie:", movie))
                NA
            }
            else if (! critic %in% critics) {
                print(paste("Error -  critic:", critic))
                NA
            }
            else {                                            
                mean_movie +
                global_baseline[global_baseline$Critic == 'movie avg - mean movie', movie][[1]] +  
                global_baseline[global_baseline$Critic == critic, 'user avg - mean movie'][[1]]
            }
}
```

## Test predictions

Sanity check a few predictions. Note, movie prediction for *Igor: HOUSE_OF_GUCCI* matches the prediction in the *My Global Baseline* sheet in input XSLX.

```{r test-predictions}
test_data <- c('HOUSE_OF_GUCCI', 'Igor', 'HOUSE_OF_GUCCI', 'Howard', 'CODA', 'Monish', 'OCEANS_8', 'Claudia')
#test_data <- c('PitchPerfect2', 'Param', 'CaptainAmerica', 'Burton', 'JungleBook', 'Vuthy', 'Frozen', 'Steve')

for (i in seq(1, length(test_data), 2)) {
                        if (! test_data[i] %in% colnames(global_baseline)) {
                            print(paste("*Error - invalid movie:", test_data[i]))
                        }
                        else if (! test_data[i + 1] %in% critics) {
                            print(paste("*Error - invalid critic:", test_data[i + 1]))
                        }
                        else {
                            print(
                                paste(
                                "Rating for movie", test_data[i], "by critic", test_data[i + 1], "- Predicted:", 
                                me.predictRating(test_data[i], test_data[i + 1]), 
                                ", Actual:", 
                                global_baseline[global_baseline$Critic == test_data[i + 1], test_data[i]]))
                        }
}
```

## Predict rating for all unrated movies

Make rating predictions for all unrated movies.

```{r predict-rating-for-all-unrated}
c <- as.character(c()) # critics
m <- as.character(c()) # movies
r <- as.numeric(c())   # predictions

for (critic in critics) {
    for (movie in movies) {
        if (is.na(global_baseline[global_baseline$Critic == critic, movie][[1]])) {
            m <- append(m, movie)
            c <- append(c, critic)
            r <- append(r, me.predictRating(movie, critic))
        }
    }
}
predictions <- data.frame('Critic' = c, 'Movie' = m, 'Predicted Rating' = r)
predictions <- predictions %>%
    group_by(Critic)
```

## Output movie predictions

Display all predictions. Note, OUSE_OF_GUCCI rating prediction for Igor, 4.22, matches the prediction in model.

```{r display-predictions}
print(predictions, n = nrow(predictions))
```

