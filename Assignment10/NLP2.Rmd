---
title: "Assignment 10 - Sentiment Analysis"
author: "Jawaid Hakim"
date: "`r Sys.Date()`"
output:
  
  pdf_document: 
    toc: true
    toc_depth: 3
    number_sections: true
  html_document:
    
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: true
boxlinks: true
urlcolor: blue
always_allow_html: true
editor_options: 
  chunk_output_type: console
---

# Load libraries

```{r setup, include=TRUE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidytext)
library(textdata)
```

# Introduction

Select fairy tales written by Hans Christian Andersen, available in the [hcandersenr] (<https://CRAN.R-project.org/package=hcandersenr>) package.

Notice, there are no chapters in these short stories. Furthermore, number (span) of sentences used for sentiment trend analysis will be shorter than span for novels.

Use [Syuzhet](https://cran.r-project.org/web/packages/syuzhet/vignettes/syuzhet-vignette.html) sentiment lexicon.

```{r}
library(syuzhet)     # sentiment lexicon
library(hcandersenr) # Stories (English) of Hans Christian Andersen
```

## Tidy data

Read all stories of Hans Christian Andersen into data frame with 'tidy' principles - one word per row. Add line and chapter numbers to each row.

```{r}
tidy_books <- hcandersen_en %>%
  group_by(book) %>%
  mutate(
    linenumber = row_number(),
    chapter = cumsum(str_detect(text, 
                                regex("^chapter [\\divxlc]", 
                                      ignore_case = TRUE)))) %>%
    ungroup() %>%
    unnest_tokens(word, text)

glimpse(tidy_books)
```

Select 'The fir tree' story.

```{r}
the_fir_tree <- tidy_books %>% 
  filter(book == "The fir tree")

the_fir_tree
```

Whereas in novels of Jane Austen we considered sentence spans of length 80, in these short stories we can expect the sentiment to fluctuate within a shorter senetence span. Here we will use a span of 15 sentences for grouping sentiment.

Create sentiment scores using AFINN, NRC, and bing lexicons.  

```{r}
sent_run_length <- 15

afinn <- the_fir_tree %>% 
  inner_join(get_sentiments("afinn"), 
             by = "word") %>% 
  group_by(index = linenumber %/% sent_run_length) %>% 
  summarise(sentiment = sum(value)) %>% 
  mutate(method = "AFINN")

bing_and_nrc <- bind_rows(
  the_fir_tree %>% 
    inner_join(get_sentiments("bing"), 
               by = "word") %>%
    mutate(method = "Bing et al."),
    the_fir_tree %>% 
    inner_join(get_sentiments("nrc") %>% 
                 filter(sentiment %in% c("positive", 
                                         "negative")),
               by = "word"
               ) %>%
    mutate(method = "NRC")) %>%
  count(method, 
        index = linenumber %/% sent_run_length, sentiment) %>%
  pivot_wider(names_from = sentiment,
              values_from = n,
              values_fill = 0) %>% 
  mutate(sentiment = positive - negative)

```

Add sentiment score using the Syuzhet sentiment lexicon.

```{r}
syuzhet <- the_fir_tree %>% 
  inner_join(syuzhet::get_sentiment_dictionary(), 
             by="word") %>% 
  group_by(index = linenumber %/% sent_run_length) %>% 
  summarise(sentiment = sum(value)) %>% 
  mutate(method = "SYUZHET")

glimpse(syuzhet)
```

Plot sentiment analysis for The fir tree.

```{r}
bind_rows(afinn, 
          bing_and_nrc, syuzhet) %>%
  ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~method, ncol = 1, scales = "free_y")
```

There are 156 books in this collection. Too many to plot together!

```{r}
NROW(unique(hcandersen_en$book))
```

Let's select 5 books at random for sentiment analysis using Syuzhet sentiment lexicon.

```{r}
books <- c('Aunty', 'The windmill', 'Moving day', 'Two brothers', 'The fir tree')

tidy_books_5 <- hcandersen_en %>%
  filter(book %in% books) %>%
  group_by(book) %>%
  mutate(
    linenumber = row_number(),
    chapter = cumsum(str_detect(text, 
                                regex("^chapter [\\divxlc]", 
                                      ignore_case = TRUE)))) %>%
    ungroup() %>%
    unnest_tokens(word, text)

hca_sentiment <- tidy_books_5 %>%
  inner_join(syuzhet::get_sentiment_dictionary()) %>% 
  mutate(sentiment = value) %>%
  select(-value) %>%
  count(book, index = linenumber %/% sent_run_length, sentiment) #%>%
  #pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) 

```

Plot.

```{r}
ggplot(hca_sentiment, aes(index, sentiment, fill = book)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~book, ncol = 1, scales = "free_x")
```

Create a worlcloud of top 100 works (minus stopwords) from all stories of Hans Christian Andersen.

```{r}
library(wordcloud)

tidy_books %>%
  anti_join(stop_words, by = "word") %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100, scale = c(2.5, 0.25)))
```

# Citations
Code used in this Rmd has been sourced from the [Chapter 2](https://www.tidytextmining.com/sentiment.html) of the book Text Mining with R by Juilia Silge and David Robinson.
